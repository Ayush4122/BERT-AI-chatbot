import streamlit as st
import PyPDF2
import torch
from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering
import numpy as np
import re
import faiss
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from numpy.linalg import norm

class DocumentProcessor:
    def __init__(self, chunk_size: int = 200, chunk_overlap: int = 50):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def clean_text(self, text: str) -> str:
        """Clean and normalize text."""
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^\w\s.,!?;:]', ' ', text)
        return text.strip()

    def tokenize_text(self, text: str) -> list:
        """Tokenize text into words."""
        return simple_preprocess(text, deacc=True)

    def simple_split_into_sentences(self, text: str) -> list:
        """Split text into sentences using simple rules."""
        sentences = re.split(r'(?<=[.!?])\s+', text)
        return [s.strip() for s in sentences if s.strip()]

    def create_chunks(self, text: str) -> list:
        """Create overlapping chunks of text."""
        sentences = self.simple_split_into_sentences(text)
        chunks = []
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_length = len(sentence.split())
            
            if current_length + sentence_length <= self.chunk_size:
                current_chunk.append(sentence)
                current_length += sentence_length
            else:
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
                current_chunk = []
                current_length = 0
                current_chunk.append(sentence)
                current_length = sentence_length
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks

    def process_pdf(self, pdf_file) -> list:
        """Process PDF and return cleaned, chunked text."""
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"

            cleaned_text = self.clean_text(text)
            chunks = self.create_chunks(cleaned_text)
            
            return chunks
        except Exception as e:
            st.error(f"Error processing PDF: {str(e)}")
            return None

class Word2VecVectorStore:
    def __init__(self, vector_size=100, window=5, min_count=1):
        self.vector_size = vector_size
        self.window = window
        self.min_count = min_count
        self.model = None
        self.index = None
        self.chunks = None

    def train_word2vec(self, chunks: list):
        """Train Word2Vec model on the chunks."""
        # Tokenize all chunks
        tokenized_chunks = [simple_preprocess(chunk) for chunk in chunks]
        
        # Train Word2Vec model
        self.model = Word2Vec(sentences=tokenized_chunks,
                            vector_size=self.vector_size,
                            window=self.window,
                            min_count=self.min_count,
                            workers=4)
        
    def get_chunk_embedding(self, chunk: str) -> np.ndarray:
        """Get embedding for a chunk of text."""
        tokens = simple_preprocess(chunk)
        token_embeddings = []
        
        for token in tokens:
            if token in self.model.wv:
                token_embeddings.append(self.model.wv[token])
        
        if not token_embeddings:
            return np.zeros(self.vector_size)
        
        # Average word embeddings to get chunk embedding
        chunk_embedding = np.mean(token_embeddings, axis=0)
        # Normalize the embedding
        chunk_embedding = chunk_embedding / norm(chunk_embedding)
        return chunk_embedding

    def create_index(self, chunks: list):
        """Create FAISS index from text chunks."""
        try:
            # Train Word2Vec model first
            self.train_word2vec(chunks)
            
            # Create progress bar
            total_chunks = len(chunks)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Process chunks and update progress
            embeddings = []
            for i, chunk in enumerate(chunks):
                status_text.text(f'Processing chunk {i+1}/{total_chunks}')
                embedding = self.get_chunk_embedding(chunk)
                embeddings.append(embedding)
                progress_bar.progress((i + 1) / total_chunks)
            
            # Convert to numpy array
            embeddings = np.array(embeddings).astype('float32')
            
            # Create FAISS index
            self.index = faiss.IndexFlatL2(self.vector_size)
            self.index.add(embeddings)
            self.chunks = chunks
            
            # Clean up progress indicators
            status_text.empty()
            progress_bar.empty()
            
        except Exception as e:
            st.error(f"Error creating index: {str(e)}")
            return None

    def search(self, query: str, k: int = 3) -> list:
        """Search for relevant chunks."""
        try:
            query_embedding = self.get_chunk_embedding(query)
            D, I = self.index.search(query_embedding.reshape(1, -1).astype('float32'), k)
            return [(self.chunks[i], score) for i, score in zip(I[0], D[0])]
        except Exception as e:
            st.error(f"Error during search: {str(e)}")
            return []

def main():
    st.title("ðŸ“š PDF Question Answering System")
    
    # Initialize models
    if 'processor' not in st.session_state:
        st.session_state.processor = DocumentProcessor()
        st.session_state.vector_store = Word2VecVectorStore()
        st.session_state.qa_model = QuestionAnswerer()
    
    # File upload
    uploaded_file = st.file_uploader("Upload a PDF file", type="pdf")
    
    if uploaded_file is not None:
        # Process PDF if not already processed
        if 'processed_file' not in st.session_state or st.session_state.processed_file != uploaded_file.name:
            with st.spinner('Processing PDF... Please wait.'):
                chunks = st.session_state.processor.process_pdf(uploaded_file)
                if chunks:
                    st.session_state.vector_store.create_index(chunks)
                    st.session_state.processed_file = uploaded_file.name
                    st.success('PDF processed successfully! You can now ask questions.')
        
        # Question input
        question = st.text_input("Ask a question about the PDF:", 
                               help="Type your question here and press Enter")
        
        if question:
            with st.spinner('Finding answer...'):
                results = st.session_state.vector_store.search(question)
                
                if results:
                    context = " ".join([chunk for chunk, _ in results])
                    answer, confidence = st.session_state.qa_model.get_answer(question, context)
                    
                    if answer:
                        st.markdown("### Answer:")
                        st.write(answer)
                        st.progress(confidence)
                        st.caption(f"Confidence: {confidence:.2%}")
                        
                        with st.expander("View source contexts"):
                            for i, (chunk, score) in enumerate(results, 1):
                                st.markdown(f"**Relevant text {i}:**")
                                st.write(chunk)
                                st.caption(f"Relevance score: {1/(1+score):.2%}")
                    else:
                        st.warning("Could not generate an answer. Please try rephrasing your question.")
                else:
                    st.warning("Could not find relevant information in the document.")

if __name__ == "__main__":
    main()
